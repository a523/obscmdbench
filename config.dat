#################test environment##################################################################

    # [OSCs] The IP address of the system under test's endpoint. If the configuration item [UseDomainName] is True, this item is ignored.
    # Example: OSCs = 172.20.41.3, 172.20.41.4, 172.20.41.2
    # Long connection, the system polls the OSC to establish a connection. The configuration uses a short connection, and each request randomly selects an OSC request.
    OSCs = 127.0.0.1

###################test case plan##################################################################

    # Configure the test case, and the corresponding operation of the use case is as follows.
    Testcase = 101
    
    # test users number, 1 user corresponds to a line of user information in users.dat
    Users = 10
    # Load the user's starting line number from user.dat, starting from 0, blank line skipping is not counted.
    UserStartIndex = 0
    
    # Concurrency of each user, the default is 1, indicating that 1 user corresponds to 1 concurrent. 1 concurrent means 1 thread.
    # If the configuration item [LongConnection] is True, one uses one HTTP/HTTPs connection repeatedly.
    ThreadsPerUser = 1
    
    
    # Testcase reference
        # 100 = ListUserBuckets
        # 101 = CreateBucket
        # 102 = ListObjectsInBucket
        # 103 = HeadBucket
        # 104 = DeleteBucket
        # 105 = BucketDelete
        # 106 = OPTIONSBucket
        # 111 = PutBucketVersioning
        # 112 = GetBucketVersioning
        # 141 = PutBucketWebsite
        # 142 = GetBucketWebsite
        # 143 = DeleteBucketWebsite
        # 151 = PutBucketCORS
        # 152 = GetBucketCORS
        # 153 = DeleteBucketCORS
        # 161 = PutBucketTag
        # 162 = GetBucketTag
        # 163 = DeleteBucketTag
        # 164 = PutBucketLog #PutBucketAcl authorization must be executed first
        # 165 = GetBucketLog
        # 167 = PutBucketStorageQuota
        # 168 = GetBucketStorageQuota
        # 170 = PutBucketAcl
        # 171 = GetBucketAcl
        # 173 = PutBucketPolicy
        # 174 = GetBucketPolicy
        # 175 = DeleteBucketPolicy
        # 176 = PutBucketLifecycle
        # 177 = GetBucketLifecycle
        # 178 = DeleteBucketLifecycle
        # 179 = PutBucketNotification
        # 180 = GetBucketNotification
        # 182 = GetBucketMultiPartsUpload
        # 185 = GetBucketLocation
        # 188 = GetBucketStorageInfo
        # 201 = PutObject
        # 202 = GetObject
        # 203 = HeadObject
        # 204 = DeleteObject
        # 205 = DeleteMultiObjects
        # 206 = CopyObject
        # 207 = RestoreObject #Retrieve the cold object
        # 211 = InitMultiUpload
        # 212 = UploadPart
        # 213 = CopyPart
        # 214 = CompleteMultiUpload
        # 215 = AbortMultiUpload
        # 216 = MultiPartsUpload # Each concurrent order completes multi-segment initialization of each object -> upload segment -> merge segment, the difference with 900 MixOperation = 211, 212, 213: 900 initializes all object segments and then uploads segments.
        # 217 = GetObjectUpload  # Need to execute InitMultiUpload first
        # 218 = PutObjectAcl
        # 219 = GetObjectAcl
        # 221 = OptionsObject
        # 226 = PostObject
        # 900 = MixOperation

############# "100=ListUserBuckets" ############################################## ####################################################

    # The number of concurrent requests is valid only for the 100=ListUserBuckets operation.
    RequestsPerThread = 2000


############# "101=CreateBucket" ############################################### #####################################################

    # Number of buckets to be created by each user: >=0, if it exceeds 100, the system will return a 409 error. To avoid mixed business conflicts, all buckets are created once per concurrent per user.
    BucketsPerUser = 10
    # Specify the bucket location when creating, cannot contain spaces, and empty means not specified.
    BucketLocation =
    # Create a bucket to specify an ACL.
    # private | public-read |public-read-write | authenticated-read |
    # bucket-owner-read | bucket-owner-full-control, empty without carrying
    # If you specify non-empty, the header field is carried in the request to create a bucket. x-amz-acl: Corresponding to acl
    CreateWithACL = public-read-write
    # Custom ID in the bucket name, the system automatically generates the bucket name format:
    # user ak lowercase +'.' + bucketNamePrefix + '.' + index, index from 0 to BucketsPerUser-1
    BucketNamePrefix = bucket.test
    # Create a bucket to specify x-default-storage-class, optional: STANDARD, STANDARD_IA and GLACIER, or STANDARD, STANDARD_IA, GLACIER multiple selection, the system will randomly select the type from
    StorageClass =

############# "102=ListObjectsInBucket" ############################################## #########################

    # The number of objects requested at one time, corresponding to the max-keys parameter in the interface, valid from 1 to 1000, or more than 1000, but the system returns up to 1000.
    Max-keys = 1000
    # List without multiple versions.

############# "103=HeadBucket" ############################################## #####################################################

    # Head 101=All buckets created by CreateBucket.
    
############# "104=DeleteBucket" ############################################## ####################################################

    # Delete 101=All buckets created in the CreateBucket configuration.
    
############# "105=DeleteBucket" ############################################## ####################################################

    # Force delete 101=All buckets created in the CreateBucket configuration.
    
############# "106=OPTIONSBucket" ############################################### ####################################################

    # OPTIONS 101=All buckets created in the CreateBucket configuration.
    # To process OPTIONS, the bucket of OBS must already have CORS configured


############# "111=PutBucketVersioning" ############################################## ####################################################

    # PutBucketVersioning 101=All buckets created in the CreateBucket configuration.
    #bucket version status, optional value Enabled | Suspended
    VersionStatus = Enabled


############# "112=GetBucketVersioning" ############################################## ####################################################

    # GetBucketVersioning 101=All buckets created in the CreateBucket configuration.

############# "141=PutBucketWebsite" ############################################## ###########################

    RedirectHostName = example.com
    
############# "142=GetBucketWebsite" ############################################## ##########################

############# "143=DeleteBucketWebsite" ############################################## #######################

############# "151=PutBucketCORS" ###########################################

#AllowedMethodValid values GET, PUT, HEAD, POST, DELETE can take multiple methods
     # In order to ensure consistent methods, this parameter is also obtained in OPTIONSBucket and OptionsObject.
     AllowedMethod = GET


#############   "161=PutBucketTag"    #########################################################
#Authentication method must be AWSV4, ie AuthAlgorithm = AWSV4
     #Configure key-value logarithm, default 1, maximum 10
     KeyValueNumber = 10

#############   "179=PutBucketNotification"    ###################################################

    #need modify /opt/dfv/obs_service_layer/objectwebservice/osc/conf/obs_sod.properties  smn_connection = true
	
#############    "201=PutObject" ##################################################################

# Each concurrently uploads an object to its own BucketsPerUser bucket.
     #[ObjectSize]Uploaded object size (bytes)
     # Example: ObjectSize = 4096 Uploads a specified size object. 4096=4K, 104857600=100MB, 65536=64K
     # Example: ObjectSize = 0~1024 Upload a random size object. 0 ~ 1024 bytes
     # Example: ObjectSize = 0,1024,2048 Randomly upload objects of size 0,1024 or 2048.
       ObjectSize = 4096~104857600
     #ObjectSize = 10485760
     #Number of objects uploaded by each concurrent in each bucket
     ObjectsPerBucketPerThread = 1000
     # Upload the number of each object name and upload it multiple times. Mostly used for multi-version or object coverage testing.
     PutTimesForOneObj = 1
	# Upload object and specify ACL at the same time, optional: private | public-read | public-read-write | authenticated-read
    # bucket-owner-read | bucket-owner-full-control, empty without carrying
    PutWithACL = public-read

    #Object is the lexicographical order, if it is false, the system randomly generates the object name, the length is 15~1024 bytes.
    #If the object name is not a lexicographical order, the download and delete tests under the out-of-order order cannot be performed.
    ObjectLexical = true

    #If ObjectLexical is set to true, the object name format refers to the configuration item ObjectNamePartten
    ObjectNamePrefix = object.test

    #object name partten, lexicographically valid, generally not modified. If the modification is to ensure that the same configuration is used for other operations of the uploaded object.
    #Make sure processID, ObjectNamePrefix, Index 3 strings exist, the order of the fields and the connected characters (strings) can be defined.
    #Index: From 0~ObjectsPerBucketPerThread-1
    #processID: Concurrency number, starting from 0
    ObjectNamePartten = processID-ObjectNamePrefix-Index
    #If the bucket has multiple versions enabled, upload the object and write the obtained object version information under data/objv-{0...}.dat. For download and delete use.

    # Create object specified x-default-storage-class, optional: STANDARD, STANDARD_IA and GLACIER, STANDARD, STANDARD_IA, GLACIER multiple selection, the system will randomly select the type
    ObjectStorageClass =

############# "202=GetObject" ############################################## 
    # Find object processing in the following order:
    # 1) Check if the detail file generated during upload is specified. (The object name can be non-lexicographic when uploaded), such as objectDesFile=result/abc.csv
    objectDesFile =

    # 2) Check if there is any concurrent data/objv-{0...}.dat file. If the bucket is open with multiple versions, the uploaded object will automatically generate the file.
    # File records the multi-version information of the object, and reads from the file to download according to the specified version.


    # 3) Download the object according to the tool naming rules, download all objects uploaded in 201=PutObject, and the uploaded object name requires lexicographic order.

    # Specify Range download object, empty means not specified. The format refers to the http 1.1 protocol Range definition, such as optional legal values:
    # 0-9 #Request the contents of the object from 0th to 9th bytes.
    # 9- #Request the contents of the object from the ninth and subsequent bytes.
    # -200 #Request the last 200 bytes of the object content.
    # 0-1,5- #Request multiple range segments of the object's flesh.
    # Multiple ranges are separated by semicolons; Such as 0-1; 3-5; 6-10 (can be overlapped), the tool randomly selects each time.
    Range =

    # Whether to randomly acquire the switch
    # Random acquisition does not need to traverse all upload objects in 201=PutObject. This configuration is a performance test requirement. For scenes with too many objects, it is recommended to close.
    IsRandomGet = false

############# "203=HeadObject" ############################################## 

     #If 201 specifies objectDesFile, the object name is obtained from the file.
    
     # Otherwise, Head 201=All objects uploaded in PutObject.
#############    "204=DeleteObject" ################################################################
# Find object processing in the following order:
     # If 201 specifies objectDesFile, the object name is obtained from the file.
     # If there is an object multi-version record under data/objv-{0...}.dat, the read from the file is deleted according to the specified version.
     # Delete 201=All objects uploaded in PutObject.

     # Whether to delete randomly
     # Randomly deleted, this configuration is a performance test requirement. For scenarios with too many objects, it is recommended to close it.
     IsRandomDelete = false

#############    "205=DeleteMultiObjects"    #######################################################

     #1 The number of objects requested to be deleted, 1~100, otherwise the server returns 400 error.
     #Please ensure that the number of concurrent objects per object (ObjectsPerBucketPerThread) is an integer multiple of DeleteCountPerRequest.
     #If it is not an integer multiple, the program defaults to each bucket (ObjectsPerBucketPerThread/DeleteCountPerRequest) +1 batch delete request.
     DeleteObjectsPerRequest = 3


#############    "206=CopyObject"    ##############################################################

    # copySrcObjFixed copyDstObjFiexed BucketNameFixed    Results
    # Unspecified      Unspecified      Unspecified        Copy an object in the source bucket. The new object name is only the ObjectNamePrefix after the source object name is added.
    # Unspecified      Unspecified      Specify            Source object: traverse all buckets of all objects; target bucket: BucketNameFixed, new object name to source object name is only ObjectNamePrefix and then add .copy
    # Unspecified      Specify             *               Traverse all objects in the bucket, all copied to BucketNameFixed bucket, new object name to source object name is only ObjectNamePrefix and then add .copy
    # Specify          Specify             *               Source object: copySrcObjFixed, target object: copyDstObjFiexed (BucketNameFixed is ignored)
    # Specify          Unspecified      Unspecified        Source object: copySrcObjFixed, target object: Configured users to copy all objects in the bucket, the new object name to the source object name is only ObjectNamePrefix and then add .copy
    # Specify          Unspecified      Specify            Source object: copySrcObjFixed, target object: BucketNameFixed bucket, new object name to source object name is only ObjectNamePrefix and then add .copy

    # If copySrcObjFixed is specified, the object name is required and all users have read access to the object. Leave it blank if you don't specify it.
    copySrcObjFixed =
    # If copyDstObjFiexed is specified, the target bucket is required to exist, and all users have write access to the bucket. Leave it blank if you don't specify it.
    copyDstObjFiexed =
    # Source object server-side encryption algorithm. Optional value: SSE-C | Empty, case insensitive.
    copySrcSrvSideEncryptType = SSE-C
#############    "207=RestoreObject"    ##############################################################

    RestoreDays =
    RestoreTier =

#############    "211=InitMultiUpload"    ########################################################
	
#program Initializes a multi-segment upload task for each object in each bucket
     # Record to local file data/upload_id-concurrency number.dat, format: username\t bucket name\tobject name\tuploadID\n
     # Total generation of BucketsPerUser*ObjectsPerBucketPerThread multi-segment tasks

     # Initialize multi-session task specified x-default-storage-class, optional: STANDARD, STANDARD_IA and GLACIER, STANDARD, STANDARD_IA, GLACIER multiple selection, the system will randomly select the type
     MultiUploadStorageClass =	

#############    "212=UploadPart"    ############################################################

    # Upload Parts For Each UploadID segments of size for each uploadID in the data/upload_id-concurrency number.dat.
    # Record to local file data/parts_etag-concurrency number.dat, format: bucket name object name uploadID partNo: Etag, partNo: Etag,...\n
    # The number of segments to upload for each uploadID [1~10000]. If the ConcurrentUpParts configuration is turned on, it needs to be configured as an integer multiple of ThreadsPerUser, otherwise the tool will automatically modify the value.
    PartsForEachUploadID = 3

    # For each uploadID, whether to upload segments concurrently. Please keep off when mixing 211, 212, 213 in 900.
    # If the switch is on, you need to configure the relationship to be satisfied: PartsForEachUploadID = x * ThreadsPerUser (x is >=1 integer). If the tool is not satisfied, the PartForEachUploadID is automatically adjusted to the closest value.
    # The single uploadID concurrency tool defaults to ThreadsPerUser
    ConcurrentUpParts = false

    # [PartSize] The size of the uploaded segment, the obs protocol requires a minimum of 5M
    # Example: PartSize = 5242880 Upload the specified size segment. 5242880=5M, 104857600=100MB
    # Example: PartSize = 5242880~10485760 Random range
    # Example:PartSize = 5242880,10485760 Optional Random Values
    PartSize = 5242880

    # Uploads per segment, multiple uploads. Mostly used for segment coverage testing.
    PutTimesForOnePart = 1

#############    "213=CopyPart"    ############################################################

# The program copies the segments of PartsForEachUploadID size for each uploadID in uploadID.dat.
     # Configure the parameters PartsForEachUploadID, PartSize is the same as 212=UploadPart.
     # Server-side encryption uses the parameters to configure the same copy object.
     # The object name of the source segment must be read from the file specified by objectDesFile in 202, and a random copy of the file is selected from the inside. It is necessary to ensure that the source object exists, the requester has read permission, and the size is not less than the target segment.

#############    "214=CompleteMultiUpload"    ################################################
     # Combine segments for each segment task. The merged segment list is read from partsEtag.dat.

#############    "215=AbortMultiUpload"    ################################################

     # Cancel the segment task, because only the segment task that has been initialized can be canceled. It is necessary to ensure the same user and concurrent configuration as the initialization segment use case.
     # The segment task list to be canceled is obtained from the local file local file data/upload_id-concurrency number .dat written when the segment task is initialized.

#############    "215=AbortMultiUpload"    ################################################

     # Cancel the segment task, because only the segment task that has been initialized can be canceled. It is necessary to ensure the same user and concurrent configuration as the initialization segment use case.
     # The segment task list to be canceled is obtained from the local file local file data/upload_id-concurrency number .dat written when the segment task is initialized.

#############    "216=MultiPartsUpload"    ################################################

    # Multi-segment initialization of objects in each concurrent order -> upload section -> merge section
	
	
#############    "900=MixOperation"     ########################################################

     # Set the mixed operation type, you can set all the operations except 900 above.
     # There are dependencies between the order of operations, such as the download object depends on the upload object.
     # Operation model is: each user runs independently, and the following loop operations are performed in sequence, the number of loops mixLoopCount
     # To ensure that various services are mixed in the system at each moment, you can configure the number of operations for each operation, and increase the number of loops and the number of concurrent users.
     MixOperations = 100,101,104,201,102,202,203,204,103
     # Cycles
     MixLoopCount = 10

######    Advanced Configuration    ############################################################

    # Fixed bucket name, default is empty. If configured, all concurrent operations are performed on the bucket name.
    # Example: BucketNameFixed = fixedbucket-01
    BucketNameFixed =

    # Fixed object name, the default is empty. If configured, all concurrent operations operate on the object name. The number of original operations does not affect.
    # Example: ObjectNameFixed = fixedObject-01
    ObjectNameFixed =

    #Authentication signature algorithm, optional AWSV2 | AWSV4 | Empty
    # If the server encryption function is enabled, the tool uses the AWSV4 algorithm by default.
    # Keep empty: Randomly request, randomly select the algorithm for each request.
    AuthAlgorithm = AWSV2
    # Request the Region name, which is mandatory when using the AWSV4 algorithm and the environment is configured in Multi-Region mode.
    Region =
    
    # Whether to use a domain name. If you use a domain name, the system will get the OSC from the domain name.
    UseDomainName = false
    # Whether to use the virtual host mode request, if you use the virtual host mode, you need to ensure that the domain name is configured correctly.
    VirtualHost = false
    # domain address
    DomainName = obs.huawei.com

    # Use HTTP or HTTPs request.
    IsHTTPs = false
    
    # ssl Protocol version number configuration, effective when IsHTTPs is True.
    # Optional values ​​include: TLSv1, TLSv1_1, TLSv1_2, SSLv23, SSLv2, SSLv3 (not configured by default to SSLv23)
    # If python version < 2.7.9, TLSv1_1, TLSv1_2 is not supported.
    # TLSv1 : Select TLS v1.0 protocol.
    # TLSv1_1 : Requires openssl version 1.0.1+, python >2.7.9
    # TLSv1_2 : The current security protocol. Need openssl version 1.0.1+, python >2.7.9
    # SSLv23: Auto-negotiate the most secure protocol.
    # SSLv2 : If the openssl is compiled with the OPENSSL_NO_SSL2 parameter is not available. The agreement is not secure and has been deprecated.
    # SSLv3 : If the openssl is compiled with the OPENSSL_NO_SSL3 parameter is not available. The agreement is not secure and has been deprecated.
    
    sslVersion =
    
    # Server-side data encryption method, if not enabled, remains empty. Optional value: SSE-KMS|SSE-C, case insensitive.
    # If SSE-C is configured, x-amz-server-side-encryption-customer-key uses the last 32 characters of the object name, and less than 32 is preceded by 0.
    SrvSideEncryptType =
    # Specify the server encryption algorithm, which is valid only when SrvSideEncryptType is SSE-KMS. Optional: aws:kms, AES256.
    SrvSideEncryptAlgorithm = aws:kms
    # Specify KMS master encryption key ID, valid only when SrvSideEncryptType is SSE-KMS and SrvSideEncryptAlgorithm is aws:kms. If not specified, the server uses the default ID.
    SrvSideEncryptAWSKMSKeyId =
    # Specify the server to encrypt the context, which is optional.
    SrvSideEncryptContext =

    # Whether to reuse the connection. If True is configured, each user initiates a connection, and the user exits to release the connection, requesting a multiplex connection each time.
    # If the configuration uses a short connection, the connection is temporarily created before each request.
    LongConnection = true

    # http header connection value sent by the client, optional: keep-alive | close, when left empty, the tool automatically adds according to LongConnection.
    ConnectionHeader =

    #Connection establishment/request wait timeout.
    ConnectTimeout = 180

    #Upload download whether to calculate MD5, if True, calculate the verification MD5 when the object is uploaded and downloaded and record it in result/******_detail.csv. If the data verification fails, the tool reports error code 9901.
    CalHashMD5 = false

    #Statistic result time period (unit: ms), according to this time period, the system gives the percentage of requests for each time period.
    # Best not to exceed 5 values. #系统 will give similar statistics based on this value:
    # <=500(90.3%), <=1000(94.9%), <=3000(98.0%), <=10000(100.0%), >10000(0.0%)
    LatencySections = 500,1000,3000,10000
    
    # Whether to record the detailed result of each request to the detail file, true|false, closing the function does not affect the performance result statistics.
    RecordDetails = true
    
    # Performance statistics interval (unit: s), 0 means off. The average response time for requests that are typically set to multiples.
    StatisticsInterval = 3

    # Performance statistics result contains error request, affecting statistical result items: avgLatency, tps, sendBPS, recvBPS
    BadRequestCounted = false
    
    # Whether to avoid multiple concurrent uploading and deleting objects in the same bucket
    AvoidSinBkOp = true
    
    #Run time (seconds)
    # Run after the specified length of time. If the specified number of requests is not completed, the tool will also exit. If the configuration is 0, it means no configuration, that is, it will exit after completing the configured number of requests.
    RunSeconds =

    # Limit the maximum number of requests per concurrent per second, which can be integer or floating point numbers, null and 0 means no limit.
    # Commonly used for requests with small response delays.
    TpsPerThread =

    # Limit the period of each concurrent operation window, if one of them is 0 or is empty, it will not take effect.
    RunWindowSeconds =
    StopWindowSeconds =

    # anonymous access, without authentication related header fields
    Anonymous = false

    # Whether to print real-time results and progress in the run. Closed when the tool is automatically invoked.
    PrintProgress = true

    # Performance statistics include the delay of each request, true|false. Turning off this function does not affect performance result statistics.
    LatencyPercentileMap = true

    # is used in conjunction with LatencyPercentileMap. If the LatencyPercentileMap is true, the point of the delay change that needs to be observed can be selected according to the situation.
    # Current demand is 10%, 50%, 90%, 95%, 99% five points.
    # Example: If 1 is concurrent, each time 100 requests are uploaded for uploading objects, then 100 objects are uploaded last. The system records the delay of each request into the list, and finally sorts the above five points according to the default requirements.
    # Get the 10th delay after sorting, the 50th delay, 90, 95, 99.
    # The system will give similar statistical results xx (10%), xx (50%), xx (90%), xx (95%), xx (99%) based on this value.
    LatencyPercentileMapSections = 10,50,90,95,99

    # Performance statistics result includes the number of delay requests, true|false
    LatencyRequestsNumber = false

    #Maximum delay and minimum delay are taken as 10
    LatencyRequestsNumberSections = 20

    # Whether to generate the HashId by ProcessName-ObjectNamePrefix-Index from ObjectNamePattern, and generate ObjectNamePattern = HashId-ProcessID-ObjectNamePrefix-Index
    ObjNamePatternHash = true

    # Whether you only need to print basic data, to reduce the main thread cpu occupation
    CollectBasicData = false

    # Run the mode of the obsPyTool tool (default is 1)
    # Mode = 1: Integrated (runs like in the past)
    # Mode = 2: Distributed (need to configure the distribute_config.dat file)
    # If it is the master server, IsMaster = true
    # If it is a child server, IsMaster = false
	Mode = 1
    IsMaster = false
